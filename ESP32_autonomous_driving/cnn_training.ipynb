{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0539f639-4daa-4d8e-b1e2-a3da46fec333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking required packages...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stall_package' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 필수 패키지 확인 및 설치\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChecking required packages...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mstall_package\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow==2.10.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m install_package(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m install_package(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stall_package' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. 패키지 자동 설치 함수\n",
    "# ---------------------------------------------------------\n",
    "def install_package(module_name, package_name=None):\n",
    "    if package_name is None:\n",
    "        package_name = module_name\n",
    "    try:\n",
    "        importlib.import_module(module_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package_name} ...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "            print(f\"{package_name} installation completed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"{package_name} installation failed (exit code {e.returncode})\")\n",
    "            sys.exit(1)\n",
    "\n",
    "# 필수 패키지 확인 및 설치\n",
    "print(\"Checking required packages...\")\n",
    "install_package(\"tensorflow\", \"tensorflow==2.10.0\")\n",
    "install_package(\"numpy\")\n",
    "install_package(\"pandas\")\n",
    "install_package(\"tqdm\")\n",
    "install_package(\"PIL\", \"Pillow\")\n",
    "install_package(\"cv2\", \"opencv-python\")\n",
    "install_package(\"matplotlib\")\n",
    "install_package(\"sklearn\", \"scikit-learn\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. 라이브러리 임포트\n",
    "# ---------------------------------------------------------\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 데이터 로드 및 전처리\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print(\"Please select the data folder window...\")\n",
    "root = tk.Tk()\n",
    "root.attributes('-topmost', True)\n",
    "root.withdraw()\n",
    "root.focus_force()\n",
    "dirname = filedialog.askdirectory(title='Select Data Folder to Train')\n",
    "root.destroy()\n",
    "\n",
    "if not dirname:\n",
    "    print(\"No folder selected. Exiting...\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"Selected Directory: {dirname}\")\n",
    "\n",
    "if not dirname.endswith('/'):\n",
    "    dirname += '/'\n",
    "\n",
    "def image_to_tensor(img_path):\n",
    "    try:\n",
    "        path = os.path.join(dirname, img_path)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"File missing: {img_path}\")\n",
    "            return None\n",
    "            \n",
    "        img = keras_image.load_img(path, target_size=(120,160))\n",
    "        x = keras_image.img_to_array(img)\n",
    "        return np.expand_dims(x, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "csv_path = os.path.join(dirname, \"0_road_labels.csv\")\n",
    "if not os.path.exists(csv_path):\n",
    "    print(f\"Error: CSV file '{csv_path}' not found in the selected folder.\")\n",
    "    sys.exit()\n",
    "\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Original data count: {len(data)}\")\n",
    "data = data[data['label'] != 4]\n",
    "print(f\"Filtered data count (removed backward): {len(data)}\")\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(\"Loading images and syncing labels...\")\n",
    "\n",
    "valid_tensors = []\n",
    "valid_labels = []\n",
    "\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    img_path = row['file']\n",
    "    label = row['label']\n",
    "    \n",
    "    tensor = image_to_tensor(img_path)\n",
    "    \n",
    "    if tensor is not None:\n",
    "        valid_tensors.append(tensor)\n",
    "        valid_labels.append(label)\n",
    "\n",
    "if len(valid_tensors) > 0:\n",
    "    tensors = np.vstack(valid_tensors)\n",
    "    targets = np.array(valid_labels)\n",
    "else:\n",
    "    print(\"Error: No valid images loaded.\")\n",
    "    sys.exit()\n",
    "\n",
    "files = data['file'].values[:len(targets)] \n",
    "\n",
    "print(f\"Final loaded tensors shape: {tensors.shape}\")\n",
    "print(f\"Final loaded targets shape: {targets.shape}\")\n",
    "\n",
    "if tensors.shape[0] != targets.shape[0]:\n",
    "    print(\"Error: Mismatch between images and labels.\")\n",
    "    sys.exit()\n",
    "# ---------------------------------------------------------\n",
    "# 4. 데이터 시각화\n",
    "# ---------------------------------------------------------\n",
    "names = ['_0_forward', '_1_right', '_2_left', '_3_stop']\n",
    "\n",
    "def display_images(img_path, ax):\n",
    "    img = cv2.imread(os.path.join(dirname, img_path))\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "count = 0\n",
    "for i in range(len(files)):\n",
    "    if count >= 4: break\n",
    "    ax = fig.add_subplot(1, 4, count + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(names[targets[i]], color='blue')\n",
    "    display_images(files[i], ax)\n",
    "    count += 1\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. 데이터셋 분리\n",
    "# ---------------------------------------------------------\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "tensors = tensors.reshape(-1,120,160,3)\n",
    "\n",
    "tensors = tensors.astype('float32')/255\n",
    "\n",
    "targets = to_categorical(targets, 4)\n",
    "\n",
    "y_indices = np.argmax(targets, axis=1) \n",
    "unique_classes, counts = np.unique(y_indices, return_counts=True)\n",
    "\n",
    "MIN_COUNT = BATCH_SIZE\n",
    "\n",
    "insufficient_classes = unique_classes[counts < MIN_COUNT]\n",
    "\n",
    "if len(insufficient_classes) > 0:\n",
    "    print(f\"\\n[경고] 데이터가 {MIN_COUNT}개 미만인 클래스(방향)를 학습에서 제외합니다: {insufficient_classes}\")\n",
    "    \n",
    "    mask = ~np.isin(y_indices, insufficient_classes)\n",
    "    \n",
    "    tensors = tensors[mask]\n",
    "    targets = targets[mask]\n",
    "    \n",
    "    print(f\"필터링 후 남은 데이터 개수: {len(targets)}\")\n",
    "else:\n",
    "    print(f\"\\n모든 클래스가 {MIN_COUNT}개 이상의 데이터를 가지고 있습니다. 필터링 없음.\")\n",
    "\n",
    "if len(targets) == 0:\n",
    "    print(\"Error: 모든 데이터가 기준 미달로 제거되었습니다.\")\n",
    "    sys.exit()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        tensors,\n",
    "        targets,\n",
    "        test_size = 0.2,\n",
    "        random_state = 1,\n",
    "        stratify=targets)\n",
    "\n",
    "n = int(len(x_test)/2)\n",
    "x_valid, y_valid = x_test[:n], y_test[:n]\n",
    "x_test, y_test = x_test[n:], y_test[n:]\n",
    "\n",
    "print(f\"Train shapes: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test shapes: {x_test.shape}, {y_test.shape}\")\n",
    "print(f\"Valid shapes: {x_valid.shape}, {y_valid.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. 모델\n",
    "# ---------------------------------------------------------\n",
    "model = tf.keras.Sequential([ # donkey car CNN style\n",
    "    tf.keras.layers.Conv2D(24, (5, 5), strides=(2, 2), padding=\"same\",\n",
    "        activation='relu', input_shape=x_train.shape[1:]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), strides=(2, 2), padding=\"same\",\n",
    "        activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\",\n",
    "        activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. 학습 실행\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# [설정 1] 목표 정확도 도달 시 종료\n",
    "class ReachTargetAccuracy(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, target_acc):\n",
    "        super(ReachTargetAccuracy, self).__init__()\n",
    "        self.target_acc = target_acc\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        if val_acc is not None and val_acc >= self.target_acc:\n",
    "            print(f\"\\n\\n검증 정확도가 목표치({self.target_acc*100:.2f}%)에 도달했습니다: {val_acc*100:.4f}%\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# [설정 2] Loss가 더 이상 안 줄어들면 종료\n",
    "early_stop_loss = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# [설정 3] Accuracy가 더 이상 안 오르면 종료\n",
    "early_stop_acc = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 목표 정확도 설정 (예: 90%)\n",
    "TARGET_ACCURACY = 0.90\n",
    "target_acc_callback = ReachTargetAccuracy(target_acc=TARGET_ACCURACY)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.05,  \n",
    "    height_shift_range=0.05, \n",
    "    zoom_range=0.05,  \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "steps = math.ceil(len(x_train) / BATCH_SIZE)\n",
    "\n",
    "callbacks_list = [early_stop_loss, early_stop_acc, target_acc_callback]\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    steps_per_epoch=steps,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "# 학습 곡선 시각화\n",
    "loss = history.history['loss']\n",
    "epochs_range = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, loss, 'g', label='Training loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(epochs_range, history.history['val_loss'], 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, history.history['accuracy'], 'b', label='Accuracy')\n",
    "if 'val_accuracy' in history.history:\n",
    "    plt.plot(epochs_range, history.history['val_accuracy'], 'orange', label='Val Accuracy')\n",
    "    plt.axhline(y=TARGET_ACCURACY, color='k', linestyle='--', label='Target')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 모델 저장\n",
    "# ---------------------------------------------------------\n",
    "current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "filename = f\"model_CNN_{current_time}.h5\"\n",
    "model.save(filename)\n",
    "print(f\"Model saved to {filename}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8. 테스트 및 검증\n",
    "# ---------------------------------------------------------\n",
    "print(\"Evaluating model...\")\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    model1 = load_model(filename)\n",
    "    print(f\"Loaded generated model: {filename}\")\n",
    "else:\n",
    "    model1 = load_model('model.h5')\n",
    "    print(\"Loaded default model: model.h5\")\n",
    "\n",
    "y_test_predict = model1.predict(x_test)\n",
    "y_test_predict = np.argmax(y_test_predict,axis=1)\n",
    "\n",
    "# 테스트 데이터 시각화\n",
    "sample_size = min(16, x_test.shape[0])\n",
    "if sample_size > 0:\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    indices = np.random.choice(x_test.shape[0], size=sample_size, replace=False)\n",
    "    for i, idx in enumerate(indices):\n",
    "        ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(np.squeeze(x_test[idx]))\n",
    "        pred_idx = y_test_predict[idx]\n",
    "        true_idx = np.argmax(y_test[idx])\n",
    "        ax.set_title(\"Pred:{} (True:{})\".format(names[pred_idx], names[true_idx]),\n",
    "            color=(\"#4876ff\" if pred_idx == true_idx else \"darkred\"))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough test data to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb4cfb-45a1-46ea-b497-492d4f8fae9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
