{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc556ed6-deb4-4ac0-84eb-33248e6a3844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. 패키지 자동 설치 함수\n",
    "# ---------------------------------------------------------\n",
    "def install_package(module_name, package_name=None):\n",
    "    if package_name is None:\n",
    "        package_name = module_name\n",
    "    try:\n",
    "        importlib.import_module(module_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package_name} ...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "            print(f\"{package_name} installation completed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"{package_name} installation failed (exit code {e.returncode})\")\n",
    "            sys.exit(1)\n",
    "\n",
    "# 필수 패키지 확인 및 설치\n",
    "print(\"Checking required packages...\")\n",
    "install_package(\"tensorflow\")\n",
    "install_package(\"numpy\")\n",
    "install_package(\"pandas\")\n",
    "install_package(\"tqdm\")\n",
    "install_package(\"PIL\", \"Pillow\")\n",
    "install_package(\"cv2\", \"opencv-python\")\n",
    "install_package(\"matplotlib\")\n",
    "install_package(\"sklearn\", \"scikit-learn\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. 라이브러리 임포트\n",
    "# ---------------------------------------------------------\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "# MobileNetV2 전용 전처리 함수 추가\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 데이터 로드 및 전처리\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print(\"Please select the data folder window...\")\n",
    "root = tk.Tk()\n",
    "root.attributes('-topmost', True)\n",
    "root.withdraw()                  \n",
    "root.focus_force()               \n",
    "dirname = filedialog.askdirectory(title='Select Data Folder to Train')\n",
    "root.destroy()\n",
    "\n",
    "if not dirname:\n",
    "    print(\"No folder selected. Exiting...\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"Selected Directory: {dirname}\")\n",
    "\n",
    "if not dirname.endswith('/'):\n",
    "    dirname += '/'\n",
    "\n",
    "def image_to_tensor(img_path):\n",
    "    try:\n",
    "        path = os.path.join(dirname, img_path)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"File missing: {img_path}\")\n",
    "            return None\n",
    "            \n",
    "        img = keras_image.load_img(path, target_size=(120, 160))\n",
    "        x = keras_image.img_to_array(img)\n",
    "        # 중요: MobileNetV2는 0~255가 아니라 -1~1 사이의 입력을 기대합니다.\n",
    "        x = preprocess_input(x) \n",
    "        return np.expand_dims(x, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# CSV 로드\n",
    "csv_path = os.path.join(dirname, \"0_road_labels.csv\")\n",
    "if not os.path.exists(csv_path):\n",
    "    print(f\"Error: CSV file '{csv_path}' not found in the selected folder.\")\n",
    "    sys.exit()\n",
    "\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# 후진 데이터(Label 4) 제거\n",
    "print(f\"Original data count: {len(data)}\")\n",
    "data = data[data['label'] != 4]\n",
    "print(f\"Filtered data count (removed backward): {len(data)}\")\n",
    "\n",
    "# 인덱스 초기화\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(\"Loading images and syncing labels...\")\n",
    "\n",
    "valid_tensors = []\n",
    "valid_labels = []\n",
    "\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    img_path = row['file']\n",
    "    label = row['label']\n",
    "    \n",
    "    tensor = image_to_tensor(img_path)\n",
    "    \n",
    "    if tensor is not None:\n",
    "        valid_tensors.append(tensor)\n",
    "        valid_labels.append(label)\n",
    "\n",
    "if len(valid_tensors) > 0:\n",
    "    tensors = np.vstack(valid_tensors)\n",
    "    targets = np.array(valid_labels)\n",
    "else:\n",
    "    print(\"Error: No valid images loaded.\")\n",
    "    sys.exit()\n",
    "\n",
    "files = data['file'].values[:len(targets)] \n",
    "\n",
    "print(f\"Final loaded tensors shape: {tensors.shape}\")\n",
    "print(f\"Final loaded targets shape: {targets.shape}\")\n",
    "\n",
    "if tensors.shape[0] != targets.shape[0]:\n",
    "    print(\"Error: Mismatch between images and labels.\")\n",
    "    sys.exit()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. 데이터 시각화\n",
    "# ---------------------------------------------------------\n",
    "names = ['_0_forward', '_1_right', '_2_left', '_3_stop']\n",
    "\n",
    "def display_images(img_path, ax):\n",
    "    img = cv2.imread(os.path.join(dirname, img_path))\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "count = 0\n",
    "for i in range(len(files)):\n",
    "    if count >= 4: break\n",
    "    ax = fig.add_subplot(1, 4, count + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(names[targets[i]], color='blue')\n",
    "    display_images(files[i], ax)\n",
    "    count += 1\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. 데이터셋 분리\n",
    "# ---------------------------------------------------------\n",
    "tensors = tensors.reshape(-1, 120, 160, 3)\n",
    "# 중요: 전처리는 위 image_to_tensor의 preprocess_input에서 이미 처리됨 (255나누기 생략)\n",
    "\n",
    "targets = to_categorical(targets, 4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        tensors,\n",
    "        targets,\n",
    "        test_size = 0.2,\n",
    "        random_state = 1)\n",
    "\n",
    "n = int(len(x_test)/2)\n",
    "x_valid, y_valid = x_test[:n], y_test[:n]\n",
    "x_test, y_test = x_test[n:], y_test[n:]\n",
    "\n",
    "print(f\"Train shapes: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test shapes: {x_test.shape}, {y_test.shape}\")\n",
    "print(f\"Valid shapes: {x_valid.shape}, {y_valid.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. 모델 정의 (MobileNetV2 Optimized Transfer Learning)\n",
    "# ---------------------------------------------------------\n",
    "print(\"Building Optimized MobileNetV2 Model...\")\n",
    "\n",
    "# 1. Base Model 로드 (ImageNet 가중치)\n",
    "base_model_full = MobileNetV2(weights='imagenet', include_top=False, input_shape=(120, 160, 3))\n",
    "\n",
    "# 2. 레이어 절단: 너무 추상적인 마지막 층 대신 'out_relu' 지점에서 특징 추출\n",
    "base_model = Model(inputs=base_model_full.input, \n",
    "                   outputs=base_model_full.get_layer('out_relu').output)\n",
    "\n",
    "# 3. 미세 조정(Fine-Tuning) 설정: 뒷부분 20개 레이어만 학습 허용\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 4. 헤드 구성 (100 -> 50 Dense 층)\n",
    "inputs = Input(shape=(120, 160, 3))\n",
    "x = base_model(inputs)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "# 5. 컴파일: 미세 조정을 위해 학습률을 낮게 설정 (0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. 학습 실행\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 데이터 증강 설정 (밝기 및 채널 이동으로 조명 변화 대응)\n",
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    channel_shift_range=20.0\n",
    ")\n",
    "\n",
    "print(\"Starting training with Optimized Settings...\")\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=32), \n",
    "    validation_data=(x_valid, y_valid),\n",
    "    steps_per_epoch=max(1, len(x_train) // 32), \n",
    "    epochs=25\n",
    ")\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 저장\n",
    "model.save(\"model.h5\")\n",
    "print(\"Model saved to model.h5\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8. 테스트 및 검증\n",
    "# ---------------------------------------------------------\n",
    "print(\"Evaluating model...\")\n",
    "# 저장된 모델 로드 시 custom 전처리가 들어갔으므로 확인을 위해 다시 로드\n",
    "model1 = load_model('model.h5')\n",
    "\n",
    "y_test_predict = model1.predict(x_test)\n",
    "y_test_predict = np.argmax(y_test_predict, axis=1)\n",
    "\n",
    "# 테스트 데이터 시각화 (이미 preprocess_input이 적용된 상태이므로 시각화를 위해 역산 혹은 원본 사용 권장하나 여기서는 단순 출력)\n",
    "sample_size = min(16, x_test.shape[0])\n",
    "if sample_size > 0:\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    indices = np.random.choice(x_test.shape[0], size=sample_size, replace=False)\n",
    "    for i, idx in enumerate(indices):\n",
    "        ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        # 시각화를 위해 -1~1 범위를 다시 0~1로 임시 변환하여 보여줌\n",
    "        temp_img = (x_test[idx] + 1.0) / 2.0\n",
    "        ax.imshow(np.clip(temp_img, 0, 1))\n",
    "        \n",
    "        pred_idx = y_test_predict[idx]\n",
    "        true_idx = np.argmax(y_test[idx])\n",
    "        ax.set_title(\"{} ({})\".format(names[pred_idx], names[true_idx]),\n",
    "            color=(\"#4876ff\" if pred_idx == true_idx else \"darkred\"))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough test data to visualize.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
